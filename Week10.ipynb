{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEGg5GB45nce",
        "outputId": "6739be5c-6f5f-48eb-f549-89d0d0f92b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vaderSentiment) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2025.11.12)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/126.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VaderAnalyzer\n"
      ],
      "metadata": {
        "id": "FZpd1ghmy5zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VaderAnalyzer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# NLTK Downloads\n",
        "# =========================\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# =========================\n",
        "# 1) Lexicon-based sentiment (NLTK VADER)\n",
        "# =========================\n",
        "print(\"=== NLTK VADER Example ===\")\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "text = \"Python is such an amazing language!\"\n",
        "sentiment_score = sid.polarity_scores(text)\n",
        "print(text, \"->\", sentiment_score, \"\\n\")\n",
        "\n",
        "# =========================\n",
        "# 2) TextBlob sentiment\n",
        "# =========================\n",
        "print(\"=== TextBlob Example ===\")\n",
        "tb_text = \"Python is such an amazing language!\"\n",
        "analysis = TextBlob(tb_text)\n",
        "print(tb_text, \"->\", analysis.sentiment, \"\\n\")\n",
        "\n",
        "# =========================\n",
        "# 3) VaderSentiment library\n",
        "# =========================\n",
        "print(\"=== VaderSentiment Example ===\")\n",
        "analyzer = VaderAnalyzer()\n",
        "vs_text = \"Python is such an amazing language!\"\n",
        "vs_score = analyzer.polarity_scores(vs_text)\n",
        "print(vs_text, \"->\", vs_score, \"\\n\")\n",
        "\n",
        "# =========================\n",
        "# 4) TF-IDF example from slides\n",
        "# =========================\n",
        "print(\"=== TF-IDF Example ===\")\n",
        "corpus = [\n",
        "    \"The cat is on the mat.\",\n",
        "    \"The dog is in the house.\",\n",
        "    \"The mat is in the house.\"\n",
        "]\n",
        "\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer_tfidf.fit_transform(corpus)\n",
        "feature_names = vectorizer_tfidf.get_feature_names_out()\n",
        "\n",
        "for doc_index, doc in enumerate(tfidf_matrix.toarray()):\n",
        "    print(f\"Document {doc_index + 1}:\")\n",
        "    for term_index, value in enumerate(doc):\n",
        "        if value > 0:\n",
        "            print(f\"  {feature_names[term_index]}: {value:.3f}\")\n",
        "    print()\n",
        "\n",
        "# =========================\n",
        "# 5) Naive Bayes Sentiment Classifier\n",
        "# (your given code + a few extra examples)\n",
        "# =========================\n",
        "print(\"=== Naive Bayes Sentiment Classifier (CountVectorizer) ===\")\n",
        "\n",
        "# Sample labeled dataset for training (you can extend this)\n",
        "data = [\n",
        "    (\"I love this product\", \"positive\"),\n",
        "    (\"This is terrible\", \"negative\"),\n",
        "    (\"I am not sure about this\", \"neutral\"),\n",
        "    (\"Absolutely fantastic experience\", \"positive\"),\n",
        "    (\"Worst thing I have ever bought\", \"negative\"),\n",
        "    (\"It is okay, nothing special\", \"neutral\"),\n",
        "    (\"I really like this\", \"positive\"),\n",
        "    (\"I hate this so much\", \"negative\"),\n",
        "]\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X, y = zip(*data)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# Vectorize the text data using CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X_train_counts = vectorizer.fit_transform(X_train)\n",
        "X_test_counts = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_counts, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = classifier.predict(X_test_counts)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "conf_matrix = confusion_matrix(y_test, predictions, labels=[\"positive\", \"negative\", \"neutral\"])\n",
        "class_report = classification_report(y_test, predictions)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nConfusion Matrix (labels: [positive, negative, neutral]):\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD61iHAXy4H4",
        "outputId": "5760b7ac-b9ad-4e09-d367-b513fd2c7593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NLTK VADER Example ===\n",
            "Python is such an amazing language! -> {'neg': 0.0, 'neu': 0.55, 'pos': 0.45, 'compound': 0.6239} \n",
            "\n",
            "=== TextBlob Example ===\n",
            "Python is such an amazing language! -> Sentiment(polarity=0.37500000000000006, subjectivity=0.7) \n",
            "\n",
            "=== VaderSentiment Example ===\n",
            "Python is such an amazing language! -> {'neg': 0.0, 'neu': 0.55, 'pos': 0.45, 'compound': 0.6239} \n",
            "\n",
            "=== TF-IDF Example ===\n",
            "Document 1:\n",
            "  cat: 0.481\n",
            "  is: 0.284\n",
            "  mat: 0.366\n",
            "  on: 0.481\n",
            "  the: 0.568\n",
            "\n",
            "Document 2:\n",
            "  dog: 0.506\n",
            "  house: 0.385\n",
            "  in: 0.385\n",
            "  is: 0.299\n",
            "  the: 0.598\n",
            "\n",
            "Document 3:\n",
            "  house: 0.408\n",
            "  in: 0.408\n",
            "  is: 0.317\n",
            "  mat: 0.408\n",
            "  the: 0.633\n",
            "\n",
            "=== Naive Bayes Sentiment Classifier (CountVectorizer) ===\n",
            "Accuracy: 0.00\n",
            "\n",
            "Confusion Matrix (labels: [positive, negative, neutral]):\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00       1.0\n",
            "     neutral       0.00      0.00      0.00       1.0\n",
            "    positive       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}